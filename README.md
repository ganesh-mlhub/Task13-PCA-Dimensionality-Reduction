# Task 13: PCA – Dimensionality Reduction

## Objective
To understand dimensionality reduction using Principal Component Analysis (PCA) and analyze the trade-off between variance retention and model accuracy.

## Dataset
- Sklearn Digits Dataset (8x8 images)

## Tools & Libraries
- Python
- Scikit-learn
- Matplotlib
- Google Colab

## Steps Performed
1. Loaded and visualized digits dataset
2. Scaled features using StandardScaler
3. Applied PCA with multiple components
4. Plotted explained variance
5. Reduced dimensionality
6. Trained Logistic Regression model
7. Compared accuracy before and after PCA
8. Visualized data in 2D PCA space

## Results
- PCA retained most variance with fewer features
- Accuracy remained high after dimensionality reduction

## Files
- `Task13_PCA_Dimensionality_Reduction.ipynb` – Main notebook
- `PCA_Report.pdf` – Report

## Conclusion
PCA effectively reduces feature dimensions while maintaining strong classification performance.
